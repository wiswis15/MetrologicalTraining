From 5d3475a37aa78481513fa0dd3565ed2c6c8596a9 Mon Sep 17 00:00:00 2001
From: Albert Dahan <albert@dahan.nl>
Date: Mon, 26 Sep 2016 13:12:18 +0200
Subject: [PATCH 29/97] [Gstreamer] Don't use find element for dorne videosink

---
 partner/dpi/gstreamer/ESPlayerGst.cpp         | 25 +++++++--
 partner/dpi/gstreamer/ESPlayerGst.h           |  2 +
 partner/dpi/gstreamer/PlaybackGroupNative.cpp | 51 +++++++++----------
 3 files changed, 46 insertions(+), 32 deletions(-)

diff --git a/partner/dpi/gstreamer/ESPlayerGst.cpp b/partner/dpi/gstreamer/ESPlayerGst.cpp
index e8ce282c..3bcf4f47 100644
--- a/partner/dpi/gstreamer/ESPlayerGst.cpp
+++ b/partner/dpi/gstreamer/ESPlayerGst.cpp
@@ -18,12 +18,14 @@
 #include <nrd/AppThread.h>
 #include <nrdbase/ScopedMutex.h>
 #include <nrdbase/NFErr.h>
-
+//#include <sys/stat.h>
+//#include <fcntl.h>
 
 using namespace netflix::device::esplayer;
 using namespace netflix;
 
 static const uint32_t WAIT_FOR_VIDEO_DATA = 30;
+//static int fileCount = 1;
 
 // Helper method for the GST framework.
 /* static */ void ESPlayerGst::gst_bin_need_data (GstAppSrc *src, guint length, gpointer user_data)
@@ -139,6 +141,10 @@ void ESPlayerGst::TransferBufferToGStreamer () {
     // so we drop audio samples until video pts offset is set.
     if (mPtsOffset == -1) {
       if (mMediaType == VIDEO) {
+//        gchar* filename = g_strdup_printf("/tmp/netflix-dump-%03d.h264", fileCount++);
+//        if (mRecorder == -1) mRecorder = open(filename, O_CREAT|O_WRONLY);
+//        g_free(filename);
+//        if (mRecorder != -1) ::ftruncate(mRecorder, 0);
         mPlaybackGroup->firstVideo(pSampleAttr->getPTS(), pSampleAttr->getDTS());
       }
       else {
@@ -170,7 +176,15 @@ void ESPlayerGst::TransferBufferToGStreamer () {
       GstSample* sample = gst_sample_new(gstBuffer, mAppsrcCaps, NULL, NULL);
  
       GstFlowReturn ret = gst_app_src_push_sample(GST_APP_SRC(mSrc), sample);
-
+/*
+      if (mMediaType == VIDEO && mRecorder != -1) {
+        gpointer data = NULL;
+        gsize n = 0;
+        unsigned int l = gst_buffer_get_size(gstBuffer);
+        gst_buffer_extract_dup (gstBuffer, 0, l, &data, &n);
+        ::write(mRecorder, data, l);
+      }
+*/
       gst_buffer_unref(gstBuffer);
       gst_sample_unref(sample);
 
@@ -186,7 +200,7 @@ void ESPlayerGst::TransferBufferToGStreamer () {
 ESPlayerGst::~ESPlayerGst()
 {
   setCloseThreadsFlag();
-
+//  if (mRecorder != -1) ::close(mRecorder);
   if (mAppsrcCaps) {
     gst_caps_unref(mAppsrcCaps);
   }
@@ -199,7 +213,8 @@ ESPlayerGst::ESPlayerGst() : mGstSource(NULL),
                              mPtsOffset(-1),
                              mDtsOffset(-1),
                              mInputExhausted(false),
-                             mReadyToPlay(false)
+                             mReadyToPlay(false)/*,
+                             mRecorder(-1)*/
 {
 }
 
@@ -218,7 +233,7 @@ ESPlayerGst::init(const struct StreamPlayerInitData& initData,
   NFErr err = NFErr_OK;
   ESPlayerNative::init(initData, callback, playbackGroup);
 
-  if (initData.mInitialStreamAttributes->mStreamType==VIDEO){
+  if (initData.mInitialStreamAttributes->mStreamType==VIDEO) {
     // Initialize the sample writer that we'll hand to the SDK to get access
     // units of encoded video. If this is MVC and we've requested MVC_SPLIT
     // initialize the sample writer to handle two views.
diff --git a/partner/dpi/gstreamer/ESPlayerGst.h b/partner/dpi/gstreamer/ESPlayerGst.h
index 6f49a160..9daccf68 100644
--- a/partner/dpi/gstreamer/ESPlayerGst.h
+++ b/partner/dpi/gstreamer/ESPlayerGst.h
@@ -119,6 +119,8 @@ private:
 
     GstElement *mSrc;
     GstCaps    *mAppsrcCaps;
+
+//    int mRecorder;
 };
 
 } // esplayer
diff --git a/partner/dpi/gstreamer/PlaybackGroupNative.cpp b/partner/dpi/gstreamer/PlaybackGroupNative.cpp
index af0e41fa..46213531 100644
--- a/partner/dpi/gstreamer/PlaybackGroupNative.cpp
+++ b/partner/dpi/gstreamer/PlaybackGroupNative.cpp
@@ -27,16 +27,8 @@ using namespace std;
 #include "VideoSinkGStreamer.h"
 #endif
 
-#if defined(BCM_NEXUS) || defined(HORIZON_FUSION)
-static GstElement* findElement(GstElement *element, const char* targetName);
-#endif
-
 #if defined(BCM_NEXUS)
-#define SINK_NAME "brcmvideosink"
-#define DECODER_NAME "brcmvideodecoder"
-#elif defined(HORIZON_FUSION)
-#define SINK_NAME "dornevideosink"
-#define DECODER_NAME "dornevideosink"
+static GstElement* findElement(GstElement *element, const char* targetName);
 #endif
 
 unsigned getGstPlayFlag(const char* nick)
@@ -432,11 +424,9 @@ void PlaybackGroupNative::firstVideo(llong pts, llong dts)
 
 void PlaybackGroupNative::audioFlushed()
 {
-
 }
 
-
-#if defined(BCM_NEXUS) || defined(HORIZON_FUSION)
+#if defined(BCM_NEXUS)
 // utility function for bcm nexus seek functionality
 static GstElement* findElement(GstElement *element, const char* targetName)
 {
@@ -476,25 +466,25 @@ static GstElement* findElement(GstElement *element, const char* targetName)
 
 GstClockTime PlaybackGroupNative::currentPosition()
 {
+  GstElement* videoDec = NULL;
   gint64 currentPts = GST_CLOCK_TIME_NONE;
   GstQuery* query = gst_query_new_position(GST_FORMAT_TIME);
 
 #if defined(HORIZON_FUSION)
-  GstElement* dorneVideoDec = findElement(mGstPipeline, DECODER_NAME);
-  if (gst_element_query(dorneVideoDec, query))
-    gst_query_parse_position(query, 0, &currentPts);
+    g_object_get(mGstPipeline, "video-sink", &videoDec, NULL);
+    if (!videoDec || !GST_IS_ELEMENT(videoDec))
+        return currentPts;
 #else
-  if (gst_element_query(mGstPipeline, query))
-    gst_query_parse_position(query, 0, &currentPts);
+    videoDec = mGstPipeline;
 #endif
 
-  gst_query_unref(query);
+  if (gst_element_query(videoDec, query))
+    gst_query_parse_position(query, 0, &currentPts);
 
-  if (currentPts != GST_CLOCK_TIME_NONE)
-    return currentPts;
+  gst_query_unref(query);
 
 #if defined(BCM_NEXUS)
-  GstElement* videoDec = findElement(mGstPipeline, DECODER_NAME);
+  videoDec = findElement(mGstPipeline, "brcmvideodecoder");
   if (videoDec) {
     g_object_get(videoDec, "video_pts", &currentPts, NULL);
     currentPts = (currentPts * GST_MSECOND) / 45;
@@ -583,18 +573,26 @@ void PlaybackGroupNative::updateVideoRectangle()
   if (!mNewVideoWindow || (getPlaybackState() != IPlaybackGroup::PLAY))
     return;
 
-#if defined(BCM_NEXUS) || defined(HORIZON_FUSION)
-  GstElement* videoSink = findElement(mGstPipeline, SINK_NAME);
-  if (!videoSink)
+  GstElement* videoDec = NULL;
+
+#if defined(HORIZON_FUSION)
+  g_object_get(mGstPipeline, "video-sink", &videoDec, NULL);
+#elif defined(BCM_NEXUS)
+  videoDec = findElement(mGstPipeline, "brcmvideosink");
+#else
+  return;
+#endif
+
+  if (!videoDec || !GST_IS_ELEMENT(videoDec))
     return;
 
   char rectString[64];
   sprintf(rectString,"%d,%d,%d,%d", mCurrentVideoWindow.x, mCurrentVideoWindow.y,
           mCurrentVideoWindow.width, mCurrentVideoWindow.height);
-  g_object_set(videoSink, "rectangle", rectString, NULL);
+  g_object_set(videoDec, "rectangle", rectString, NULL);
 
   int newWidth, newHeight;
-  g_object_get(videoSink, "window-width", &newWidth, "window-height", &newHeight, NULL);
+  g_object_get(videoDec, "window-width", &newWidth, "window-height", &newHeight, NULL);
   // make sure the properties are set correctly, if not try again next time.
   if (newWidth == mCurrentVideoWindow.width && newHeight == mCurrentVideoWindow.height) {
     mNewVideoWindow = false;
@@ -602,7 +600,6 @@ void PlaybackGroupNative::updateVideoRectangle()
   } else {
     Log::error(TRACE_MEDIAPLAYBACK, "failed to set the video sink rectangle! widht=%d", newWidth);
   }
-#endif
 }
 
 ESManagerNative* PlaybackGroupNative::getESManager()
-- 
2.17.1

